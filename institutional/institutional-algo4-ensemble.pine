//@version=5
indicator(title="MKN: Institutional Algo 4: Ensemble Detector", shorttitle="IA4-Ensemble", overlay=false, precision=0, max_bars_back=500)

// ============================================================================
// ULTIMATE ENSEMBLE - FULL IMPLEMENTATION
// ============================================================================
// Combines sophisticated pattern detection with regime-specific refinements:
// 1. Algorithm 1: Full 5 patterns + graduated trend filtering (from V2)
// 2. Algorithm 2: Building patterns + REGIME SCORING (from OLD)
// 3. Algorithm 3: Proper Bayesian + REGIME-SPECIFIC LIKELIHOODS (from OLD)
// 4. Pattern consensus voting from all 3 algorithms (from V2)
// ============================================================================

// ============================================================================
// LABEL DOCUMENTATION
// ============================================================================
//
// WHAT THE LABELS MEAN:
//
// Format: "[Score]\n[Agreement]\n[Pattern]"
//   Example: "85\n3/3 Algos\nACCUM" or "72\n2/3 Algos\nMIXED"
//
// Ensemble Score (0-100): Weighted average of 3 algorithms
//   - Default weights:
//     • Algorithm 1 (Volume Efficiency): 25%
//     • Algorithm 2 (MTF Convergence): 35%
//     • Algorithm 3 (Bayesian): 40%
//   - Weights are normalized (only enabled algorithms count)
//   - Customizable in settings
//
// Agreement Label: How many algorithms detected institutional activity
//   - "3/3 Algos" = All 3 algorithms agree (VERY HIGH confidence)
//   - "2/3 Algos" = Two algorithms agree (HIGH confidence)
//   - "1/3 Algos" = One algorithm only (MODERATE confidence)
//   - More agreement = stronger signal
//
// Consensus Pattern: Majority vote from all algorithms
//   - ACCUM (Accumulation) = Majority vote for institutional buying
//     • Algorithms agree it's accumulation pattern
//     • Best reliability when 3/3 or 2/3 agreement
//
//   - DISTR (Distribution) = Majority vote for institutional selling
//     • Algorithms agree it's distribution pattern
//     • Best reliability when 3/3 or 2/3 agreement
//
//   - MIXED = No clear consensus
//     • Algorithms disagree on pattern type
//     • OR only 1/3 detected activity
//     • Lower confidence, use with caution
//
// Individual Algorithm Contributions (shown in table):
//   - Algo 1 Score: Volume efficiency + pattern detection + trend filter
//   - Algo 2 Score: Multi-timeframe volume convergence + building patterns
//   - Algo 3 Score: Bayesian probability with regime-specific priors
//
// Confidence Levels:
//   - Very High: 3/3 agreement + score ≥80
//     • All methodologies confirm institutional presence
//     • Highest reliability
//
//   - High: 2/3 agreement + score ≥70
//     • Two different approaches agree
//     • Strong signal
//
//   - Moderate: 1/3 agreement OR score 60-69
//     • Single detection or weak consensus
//     • Requires additional confirmation
//
//   - Low: Score <60
//     • Below threshold or conflicting signals
//     • Not displayed by default
//
// Visual Cues:
//   - Histogram Color: Green (≥70), Yellow (50-69), Orange (<50)
//   - Label Color: Green (2-3 algos agree), Yellow (1 algo only)
//   - Label Size: Small (all labels same size)
//
// Why Use Ensemble?
//   - Combines 3 different methodologies (efficiency, MTF, Bayesian)
//   - Reduces false positives (must pass multiple tests)
//   - Higher accuracy than any single algorithm
//   - Agreement count shows signal quality
//
// Best Use:
//   - Wait for 2/3 or 3/3 agreement for highest confidence
//   - Use pattern consensus (not individual patterns)
//   - Cross-reference with S/R levels for entry/exit points
//   - Higher scores + more agreement = stronger institutional presence
//
// ============================================================================

// ============================================================================
// LIBRARY IMPORTS
// ============================================================================
import redshad0ww/CoreMath/3 as math_lib
import redshad0ww/RegimeDetection/3 as regime_lib
import redshad0ww/VolumeAnalysis/3 as vol_lib
import redshad0ww/TrendDetection/2 as trend_lib
import redshad0ww/MTFUtils/3 as mtf_lib

// ============================= INPUTS =======================================

// Ensemble Weighting
weight_efficiency = input.float(0.25, "Weight: Volume Efficiency", minval=0.0, maxval=1.0, step=0.05, group="Ensemble Weights")
weight_mtf = input.float(0.35, "Weight: MTF Convergence", minval=0.0, maxval=1.0, step=0.05, group="Ensemble Weights")
weight_bayesian = input.float(0.40, "Weight: Bayesian", minval=0.0, maxval=1.0, step=0.05, group="Ensemble Weights")

// General Settings
scoreThreshold = input.int(70, "Ensemble Score Threshold", minval=50, maxval=90, group="Scoring")
enableAlgo1 = input.bool(true, "Enable Algorithm 1 (Efficiency)", group="Algorithm Selection")
enableAlgo2 = input.bool(true, "Enable Algorithm 2 (MTF)", group="Algorithm Selection")
enableAlgo3 = input.bool(true, "Enable Algorithm 3 (Bayesian)", group="Algorithm Selection")

// Visualization
showTable = input.bool(true, "Show Ensemble Table", group="Visualization")
showComponentScores = input.bool(true, "Show Individual Algorithm Scores", group="Visualization")
showMarkers = input.bool(true, "Show Chart Markers", group="Visualization")

// ============================================================================
// ALGORITHM 1: VOLUME EFFICIENCY & ABSORPTION (FULL IMPLEMENTATION)
// ============================================================================

// Inputs
volumeLookback1 = input.int(20, "Volume Lookback", minval=10, maxval=100, group="Algo 1: Efficiency")
efficiencyThreshold1 = input.float(1.3, "Efficiency Threshold", minval=1.0, maxval=3.0, step=0.1, group="Algo 1: Efficiency")
minADX1 = input.float(25.0, "Min ADX for Trend", minval=15.0, maxval=40.0, step=1.0, group="Algo 1: Efficiency")

// Get volume metrics from library
volMetrics1 = vol_lib.calculateVolumeMetrics(volumeLookback1)
relativeVolume1 = volMetrics1.relativeVolume
volumeEfficiency1 = volMetrics1.volumeEfficiency
efficiencyRatio1 = volMetrics1.efficiencyRatio
volumeScore1 = volMetrics1.volumeScore

// Calculate efficiency score
efficiencyScore1 = efficiencyRatio1 >= efficiencyThreshold1 and efficiencyRatio1 <= 4.0 ?
     math.min(30, (efficiencyRatio1 - 1.0) * 15.0) : 0.0

// Price metrics
priceRange1 = high - low
bodySize1 = math.abs(close - open)
upperWick1 = high - math.max(open, close)
lowerWick1 = math.min(open, close) - low
totalWickSize1 = upperWick1 + lowerWick1
wickRatio1 = math_lib.safeDivide(totalWickSize1, priceRange1, 0.0)
wickScore1 = wickRatio1 > 0.3 ? math.min(20, wickRatio1 * 40.0) : 0.0

// Price context awareness
closePosition1 = math_lib.safeDivide(close - low, priceRange1, 0.5)
highest10_1 = ta.highest(high, 10)
lowest10_1 = ta.lowest(low, 10)
atLocalHigh1 = high >= highest10_1[1]
atLocalLow1 = low <= lowest10_1[1]
priceChange3_1 = (close - close[3]) / close[3] * 100
isRising1 = close > close[3]
isFalling1 = close < close[3]

// 5 DISTINCT PATTERN TYPES (as documented)
pattern1_type = "NONE"
controlScore1 = 0.0
accumulationPattern1 = false
distributionPattern1 = false

// Pattern 1: Classic Absorption (mid-close, compressed, high volume)
if closePosition1 >= 0.35 and closePosition1 <= 0.65 and relativeVolume1 > 1.3 and priceChange3_1 < -1.0
    controlScore1 := 12.0
    pattern1_type := "P1-Classic"
    accumulationPattern1 := true

// Pattern 2: Aggressive Accumulation (high close, high volume)
else if closePosition1 > 0.65 and relativeVolume1 > 1.8
    controlScore1 := 10.0
    pattern1_type := "P2-Aggressive"
    accumulationPattern1 := true

// Pattern 3: Distribution into Strength (high close, extreme volume)
else if closePosition1 > 0.75 and relativeVolume1 > 2.5 and isRising1
    controlScore1 := 8.0
    pattern1_type := "P3-Distribution"
    distributionPattern1 := true

// Pattern 4: Stealth Accumulation (low close, moderate volume)
else if closePosition1 < 0.40 and atLocalLow1 and relativeVolume1 > 1.2 and relativeVolume1 < 2.0
    controlScore1 := 7.0
    pattern1_type := "P4-Stealth"
    accumulationPattern1 := true

// Pattern 5: High Volume Test (any close, very high volume)
else if relativeVolume1 > 1.5
    controlScore1 := 6.0
    pattern1_type := "P5-Test"
    // Neutral - could be either

// Trend detection (for filtering)
[isUptrend1, isDowntrend1, isRanging1] = trend_lib.detectEMATrend(20, 50, 200)
trendData1 = trend_lib.detectADXTrend(14, minADX1, 35.0)
adx1 = trendData1.adxValue
isTrending1 = trendData1.isTrending
isStrongTrend1 = trendData1.isStrongTrend

// Calculate raw score
rawScore1 = volumeScore1 + efficiencyScore1 + wickScore1 + controlScore1
baseScore1 = math.min(100, math.max(0, rawScore1))

// TREND FILTERING (±10-50% adjustment - GRADUATED from V2)
trendAligned1 = (accumulationPattern1 and isUptrend1) or (distributionPattern1 and isDowntrend1)
trendOpposed1 = (accumulationPattern1 and isDowntrend1) or (distributionPattern1 and isUptrend1)

trendMultiplier1 = 1.0
if trendAligned1 and isStrongTrend1
    trendMultiplier1 := 1.50  // +50% for strong aligned trend
else if trendAligned1 and isTrending1
    trendMultiplier1 := 1.25  // +25% for moderate aligned trend
else if trendAligned1
    trendMultiplier1 := 1.10  // +10% for weak aligned trend
else if trendOpposed1 and isStrongTrend1
    trendMultiplier1 := 0.50  // -50% for strong opposed trend
else if trendOpposed1
    trendMultiplier1 := 0.75  // -25% for opposed trend

algo1_score = enableAlgo1 ? math.min(100, baseScore1 * trendMultiplier1) : 0.0

// Pattern classification for Algo 1
algo1_pattern = accumulationPattern1 ? "ACCUM" : distributionPattern1 ? "DISTR" : "MIXED"

// ============================================================================
// ALGORITHM 2: MULTI-TIMEFRAME CONVERGENCE (ENHANCED WITH REGIME)
// ============================================================================

// Inputs
volumeLookback2 = input.int(20, "Volume Lookback", minval=10, maxval=100, group="Algo 2: MTF")
volumeThreshold2 = input.float(1.5, "Volume Threshold (All TF)", minval=1.0, maxval=5.0, step=0.1, group="Algo 2: MTF")
useRegimeFilter2 = input.bool(true, "Enable Regime Scoring", group="Algo 2: MTF")
atrLength2 = input.int(14, "ATR Length", minval=7, maxval=50, group="Algo 2: MTF")
atrLookback2 = input.int(50, "ATR Regime Lookback", minval=20, maxval=100, group="Algo 2: MTF")

// Get higher timeframes from library
higherTF1 = mtf_lib.getHigherTimeframe(timeframe.period)
higherTF2 = mtf_lib.getSecondHigherTimeframe(timeframe.period)

// Current TF volume metrics
volMetrics2 = vol_lib.calculateVolumeMetrics(volumeLookback2)
currentRelVol = volMetrics2.relativeVolume

// HTF volume metrics
[htf1Volume, htf1AvgVolume, htf1Close, htf1High, htf1Low] = request.security(syminfo.tickerid, higherTF1,
     [volume, ta.sma(volume, volumeLookback2), close, high, low], lookahead=barmerge.lookahead_off)
[htf2Volume, htf2AvgVolume, htf2Close, htf2High, htf2Low] = request.security(syminfo.tickerid, higherTF2,
     [volume, ta.sma(volume, volumeLookback2), close, high, low], lookahead=barmerge.lookahead_off)

htf1RelVol = math_lib.safeDivide(htf1Volume, htf1AvgVolume, 1.0)
htf2RelVol = math_lib.safeDivide(htf2Volume, htf2AvgVolume, 1.0)

// MTF Convergence scoring (0-40 pts)
convergenceScore2 = 0.0
tfCount = 0
if currentRelVol > volumeThreshold2
    tfCount := tfCount + 1
if htf1RelVol > volumeThreshold2
    tfCount := tfCount + 1
if htf2RelVol > volumeThreshold2
    tfCount := tfCount + 1

convergenceScore2 := tfCount == 3 ? 40.0 : tfCount == 2 ? 25.0 : tfCount == 1 ? 10.0 : 0.0

// BUILDING PATTERN DETECTION (0-20 pts)
buildingPatternScore2 = 0.0
isBuildingPattern2 = false

// Cascade pattern: volumes increase from HTF2 → HTF1 → Current
if htf2RelVol > 1.0 and htf1RelVol > htf2RelVol and currentRelVol > htf1RelVol
    buildingPatternScore2 := 20.0
    isBuildingPattern2 := true
else if htf1RelVol > 1.0 and currentRelVol > htf1RelVol
    buildingPatternScore2 := 12.0
    isBuildingPattern2 := true
else if currentRelVol > 1.3 and htf1RelVol > 1.0
    buildingPatternScore2 := 6.0

// PRICE ACTION SCORING (0-30 pts)
priceActionScore2 = 0.0
priceRange2 = high - low
htf1Range = htf1High - htf1Low
closePosition2 = math_lib.safeDivide(close - low, priceRange2, 0.5)

// Accumulation pattern: compressed range, mid-close
if priceRange2 < ta.sma(priceRange2, 20) and closePosition2 >= 0.35 and closePosition2 <= 0.65
    priceActionScore2 := 30.0
// Distribution/Breakout: expanded range, extreme close
else if priceRange2 > ta.sma(priceRange2, 20) * 1.2 and (closePosition2 > 0.7 or closePosition2 < 0.3)
    priceActionScore2 := 25.0
// Neutral
else
    priceActionScore2 := 10.0

// TREND SCORING (0-10 pts)
[isUptrend2, isDowntrend2, isRanging2] = trend_lib.detectEMATrend(20, 50, 200)
trendScore2 = isUptrend2 or isDowntrend2 ? 10.0 : 0.0

// REGIME SCORING (0-10 pts) - FROM OLD VERSION
regimeScore2 = 0.0
if useRegimeFilter2
    // Regime detection for Algo 2
    currentATR2 = ta.atr(atrLength2)
    avgATR2 = ta.sma(ta.atr(atrLength2), atrLookback2)
    atrRatio2 = math_lib.safeDivide(currentATR2, avgATR2, 1.0)

    isHighVol2 = atrRatio2 > 1.3
    isLowVol2 = atrRatio2 < 0.7
    isNormalVol2 = not isHighVol2 and not isLowVol2

    // Transition detection
    atrChange2 = math.abs(atrRatio2 - atrRatio2[5])
    isTransitioning2 = atrChange2 > 0.2

    if isTransitioning2
        regimeScore2 := 5.0   // Reduced confidence during transitions
    else if isLowVol2
        regimeScore2 := 10.0  // Optimal for institutional activity
    else if isNormalVol2
        regimeScore2 := 7.0
    else if isHighVol2
        regimeScore2 := 0.0   // High volatility unreliable

// Total Algorithm 2 score (now includes regime)
algo2_score = enableAlgo2 ? math.min(100, convergenceScore2 + buildingPatternScore2 + priceActionScore2 + trendScore2 + regimeScore2) : 0.0

// Pattern classification for Algo 2
algo2_pattern = priceActionScore2 == 30.0 ? "ACCUM" : priceActionScore2 == 25.0 ? "DISTR" : "MIXED"

// ============================================================================
// ALGORITHM 3: BAYESIAN WITH REGIME-SPECIFIC LIKELIHOODS (FROM OLD)
// ============================================================================

// Inputs
volumeLookback3 = input.int(20, "Volume Lookback", minval=10, maxval=100, group="Algo 3: Bayesian")
volumeMultiplier3 = input.float(2.0, "High Volume Threshold", minval=1.5, maxval=5.0, step=0.1, group="Algo 3: Bayesian")
efficiencyMultiplier3 = input.float(1.5, "High Efficiency Threshold", minval=1.0, maxval=3.0, step=0.1, group="Algo 3: Bayesian")

// Get regime from library
regimeData3 = regime_lib.detectRegime(14, 50)
trendData3 = trend_lib.detectADXTrend(14, 25.0, 35.0)

// Get volume metrics
volMetrics3 = vol_lib.calculateVolumeMetrics(volumeLookback3)

// Feature detection
highVolume3 = volMetrics3.relativeVolume > volumeMultiplier3
highEfficiency3 = volMetrics3.efficiencyRatio > efficiencyMultiplier3

// Regime-based PRIORS
priorProbability = 0.20
regimeName3 = ""
if regimeData3.isLowVol and not trendData3.isTrending
    priorProbability := 0.40  // RangingLowVol - optimal
    regimeName3 := "RangingLowVol"
else if regimeData3.isLowVol and trendData3.isTrending
    priorProbability := 0.30  // TrendLowVol
    regimeName3 := "TrendLowVol"
else if regimeData3.isHighVol and not trendData3.isTrending
    priorProbability := 0.25  // RangingHighVol
    regimeName3 := "RangingHighVol"
else if regimeData3.isHighVol and trendData3.isTrending
    priorProbability := 0.15  // TrendHighVol - worst
    regimeName3 := "TrendHighVol"
else
    priorProbability := 0.20
    regimeName3 := "Normal"

// REGIME-SPECIFIC LIKELIHOODS (FROM OLD VERSION)
// P(Features | Institutional) - varies by regime
likelihoodInstitutional = 1.0

// P(Features | Not Institutional) - retail/noise varies by regime
likelihoodRetail = 1.0

// Apply regime-specific multipliers
if regimeName3 == "RangingLowVol"
    // Optimal regime - institutions prefer this
    if highVolume3
        likelihoodInstitutional := likelihoodInstitutional * 0.75
        likelihoodRetail := likelihoodRetail * 0.30
    if highEfficiency3
        likelihoodInstitutional := likelihoodInstitutional * 0.80
        likelihoodRetail := likelihoodRetail * 0.25
else if regimeName3 == "TrendHighVol"
    // High volatility trending - different patterns
    if highVolume3
        likelihoodInstitutional := likelihoodInstitutional * 0.85
        likelihoodRetail := likelihoodRetail * 0.60
    if highEfficiency3
        likelihoodInstitutional := likelihoodInstitutional * 0.60
        likelihoodRetail := likelihoodRetail * 0.40
else
    // Default/other regimes - use balanced multipliers
    if highVolume3
        likelihoodInstitutional := likelihoodInstitutional * 0.70
        likelihoodRetail := likelihoodRetail * 0.40
    if highEfficiency3
        likelihoodInstitutional := likelihoodInstitutional * 0.75
        likelihoodRetail := likelihoodRetail * 0.35

// Calculate posterior using Bayes' theorem
// P(Institutional | Features) = [P(F|I) × P(I)] / [P(F|I) × P(I) + P(F|R) × P(R)]
priorRetail = 1.0 - priorProbability
numerator = likelihoodInstitutional * priorProbability
denominator = (likelihoodInstitutional * priorProbability) + (likelihoodRetail * priorRetail)

posteriorProbability = math_lib.safeDivide(numerator, denominator, priorProbability)

// Confidence boost for strong evidence
confidenceBoost = 0.0
if highVolume3 and highEfficiency3
    confidenceBoost := 10.0

// Scale to 0-100
bayesianScore = math.min(100, (posteriorProbability * 100.0) + confidenceBoost)
algo3_score = enableAlgo3 ? bayesianScore : 0.0

// Pattern classification for Algo 3 (based on features)
algo3_pattern = highVolume3 and highEfficiency3 ? "ACCUM" : "MIXED"

// ============================================================================
// PATTERN CONSENSUS MECHANISM (as documented)
// ============================================================================

// Count pattern votes
accumVotes = 0
distrVotes = 0
mixedVotes = 0

if enableAlgo1
    if algo1_pattern == "ACCUM"
        accumVotes := accumVotes + 1
    else if algo1_pattern == "DISTR"
        distrVotes := distrVotes + 1
    else
        mixedVotes := mixedVotes + 1

if enableAlgo2
    if algo2_pattern == "ACCUM"
        accumVotes := accumVotes + 1
    else if algo2_pattern == "DISTR"
        distrVotes := distrVotes + 1
    else
        mixedVotes := mixedVotes + 1

if enableAlgo3
    if algo3_pattern == "ACCUM"
        accumVotes := accumVotes + 1
    else if algo3_pattern == "DISTR"
        distrVotes := distrVotes + 1
    else
        mixedVotes := mixedVotes + 1

// Determine consensus pattern (majority wins)
consensusPattern = "Mixed"
if accumVotes > distrVotes and accumVotes > mixedVotes
    consensusPattern := "Accumulation"
else if distrVotes > accumVotes and distrVotes > mixedVotes
    consensusPattern := "Distribution"
else
    consensusPattern := "Mixed"

// ============================================================================
// ENSEMBLE SCORE CALCULATION
// ============================================================================

// Normalize weights
totalWeight = weight_efficiency + weight_mtf + weight_bayesian
normWeight1 = math_lib.safeDivide(weight_efficiency, totalWeight, 0.33)
normWeight2 = math_lib.safeDivide(weight_mtf, totalWeight, 0.33)
normWeight3 = math_lib.safeDivide(weight_bayesian, totalWeight, 0.34)

// Calculate weighted ensemble score
ensembleScore = (algo1_score * normWeight1) + (algo2_score * normWeight2) + (algo3_score * normWeight3)
isInstitutional = ensembleScore >= scoreThreshold

// Count agreement
agreementCount = 0
if algo1_score >= 70
    agreementCount := agreementCount + 1
if algo2_score >= 70
    agreementCount := agreementCount + 1
if algo3_score >= 70
    agreementCount := agreementCount + 1

agreementLabel = agreementCount == 3 ? "Strong (3/3)" :
     agreementCount == 2 ? "Moderate (2/3)" :
     agreementCount == 1 ? "Weak (1/3)" : "None (0/3)"

// Alert variables
agreement = agreementCount
confidence = agreementCount == 3 ? "Very High" :
     agreementCount == 2 ? "High" :
     agreementCount == 1 ? "Medium" : "Low"

// Institutional type = consensus pattern
institutionalType = consensusPattern

// ============================= VISUALIZATION ================================

// Plot ensemble score
hline(scoreThreshold, "Threshold", color=color.white, linestyle=hline.style_dashed)
scoreColor = ensembleScore >= 70 ? color.green : ensembleScore >= 50 ? color.yellow : color.orange
plot(ensembleScore, "Ensemble Score", color=scoreColor, style=plot.style_histogram, linewidth=3)

// Plot individual scores if enabled
plot(showComponentScores ? algo1_score : na, "Algo 1", color=color.new(color.blue, 50), style=plot.style_line)
plot(showComponentScores ? algo2_score : na, "Algo 2", color=color.new(color.purple, 50), style=plot.style_line)
plot(showComponentScores ? algo3_score : na, "Algo 3", color=color.new(color.aqua, 50), style=plot.style_line)

// Chart markers
if showMarkers and isInstitutional
    markerColor = agreementCount >= 2 ? color.new(color.green, 20) : color.new(color.yellow, 20)
    markerText = str.tostring(math.round(ensembleScore)) + "\n" + agreementLabel + "\n" + consensusPattern
    label.new(bar_index, ensembleScore, text=markerText,
         style=label.style_label_up, color=markerColor, textcolor=color.white, size=size.small)

// Background color based on pattern
color bgColor = na
if isInstitutional
    if consensusPattern == "Accumulation"
        bgColor := color.new(color.green, 92)
    else if consensusPattern == "Distribution"
        bgColor := color.new(color.red, 92)
    else
        bgColor := color.new(color.yellow, 92)

bgcolor(bgColor, title="Signal Background")

// ============================= METRICS TABLE ================================

if showTable
    var table ensembleTable = table.new(position.top_right, 2, 15, border_width=2,
         border_color=color.new(color.gray, 50), frame_width=1, frame_color=color.new(color.gray, 50))

    // Header
    table.cell(ensembleTable, 0, 0, "Institutional Ensemble", bgcolor=color.new(color.blue, 70),
         text_color=color.white, text_size=size.normal)
    table.merge_cells(ensembleTable, 0, 0, 1, 0)

    // Ensemble score
    table.cell(ensembleTable, 0, 1, "Ensemble Score:", text_halign=text.align_left, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 1, str.tostring(math.round(ensembleScore)), text_color=scoreColor)

    // Status
    table.cell(ensembleTable, 0, 2, "Status:", text_halign=text.align_left, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 2, isInstitutional ? "✓ ACTIVE" : "○ Inactive",
         text_color=isInstitutional ? color.lime : color.new(color.white, 50))

    // Agreement
    table.cell(ensembleTable, 0, 3, "Agreement:", text_halign=text.align_left, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 3, agreementLabel,
         text_color=agreementCount >= 2 ? color.lime : color.orange)

    // Pattern Consensus
    table.cell(ensembleTable, 0, 4, "Pattern Type:", text_halign=text.align_left, text_color=color.new(color.white, 20))
    patternColor = consensusPattern == "Accumulation" ? color.lime :
         consensusPattern == "Distribution" ? color.red : color.orange
    table.cell(ensembleTable, 1, 4, consensusPattern, text_color=patternColor)

    // Separator
    table.cell(ensembleTable, 0, 5, "Component Scores:", bgcolor=color.new(color.gray, 70),
         text_color=color.white, text_size=size.small)
    table.merge_cells(ensembleTable, 0, 5, 1, 5)

    // Algorithm scores with patterns
    table.cell(ensembleTable, 0, 6, "Algo 1 (Eff):", text_halign=text.align_left, text_size=size.small, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 6, str.tostring(math.round(algo1_score)) + " [" + algo1_pattern + "]",
         text_size=size.small, text_color=algo1_score >= 70 ? color.lime : color.new(color.white, 50))

    table.cell(ensembleTable, 0, 7, "Algo 2 (MTF):", text_halign=text.align_left, text_size=size.small, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 7, str.tostring(math.round(algo2_score)) + " [" + algo2_pattern + "]",
         text_size=size.small, text_color=algo2_score >= 70 ? color.lime : color.new(color.white, 50))

    table.cell(ensembleTable, 0, 8, "Algo 3 (Bayes):", text_halign=text.align_left, text_size=size.small, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 8, str.tostring(math.round(algo3_score)) + " [" + algo3_pattern + "]",
         text_size=size.small, text_color=algo3_score >= 70 ? color.lime : color.new(color.white, 50))

    // Pattern voting breakdown
    table.cell(ensembleTable, 0, 9, "Pattern Votes:", bgcolor=color.new(color.gray, 70),
         text_color=color.white, text_size=size.small)
    table.merge_cells(ensembleTable, 0, 9, 1, 9)

    table.cell(ensembleTable, 0, 10, "Accumulation:", text_halign=text.align_left, text_size=size.small, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 10, str.tostring(accumVotes) + "/3", text_size=size.small, text_color=color.new(color.white, 50))

    table.cell(ensembleTable, 0, 11, "Distribution:", text_halign=text.align_left, text_size=size.small, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 11, str.tostring(distrVotes) + "/3", text_size=size.small, text_color=color.new(color.white, 50))

    table.cell(ensembleTable, 0, 12, "Mixed:", text_halign=text.align_left, text_size=size.small, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 12, str.tostring(mixedVotes) + "/3", text_size=size.small, text_color=color.new(color.white, 50))

    // Regime info
    table.cell(ensembleTable, 0, 13, "Regime:", text_halign=text.align_left, text_size=size.small, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 13, regimeName3, text_size=size.small, text_color=color.new(color.white, 50))

    table.cell(ensembleTable, 0, 14, "ADX:", text_halign=text.align_left, text_size=size.small, text_color=color.new(color.white, 20))
    table.cell(ensembleTable, 1, 14, str.tostring(math.round(trendData3.adxValue, 1)),
         text_size=size.small, text_color=trendData3.isTrending ? color.lime : color.new(color.white, 50))

// ============================= ALERTS =======================================

// Alert 1: Ensemble score crosses above threshold
if ta.crossover(ensembleScore, scoreThreshold)
    alert("ENSEMBLE: Institutional " + institutionalType + " detected on " + syminfo.ticker + " (Score: " + str.tostring(ensembleScore, "#") + ", Confidence: " + confidence + ")", alert.freq_once_per_bar_close)

// Alert 2: All 3 algorithms agree (high confidence)
if agreement == 3 and isInstitutional and not (isInstitutional[1] and agreement[1] == 3)
    alert("VERY HIGH CONFIDENCE: All 3 algorithms detect institutional activity on " + syminfo.ticker + " (Score: " + str.tostring(ensembleScore, "#") + ", Type: " + institutionalType + ", Pattern Consensus: " + consensusPattern + ")", alert.freq_once_per_bar_close)

// Alert 3: Signal ended
if ta.crossunder(ensembleScore, scoreThreshold)
    alert("Institutional activity ended on " + syminfo.ticker + " (Score dropped below threshold)", alert.freq_once_per_bar_close)

// Alert 4: Accumulation consensus with high agreement
if agreement >= 2 and consensusPattern == "Accumulation" and isInstitutional and
     not (isInstitutional[1] and agreement[1] >= 2 and consensusPattern[1] == "Accumulation")
    alert("ACCUMULATION CONSENSUS: " + str.tostring(accumVotes) + "/3 algorithms detect accumulation on " + syminfo.ticker + " (Score: " + str.tostring(ensembleScore, "#") + ", Regime: " + regimeName3 + ")", alert.freq_once_per_bar_close)
